{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training file for any model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform \n",
    "\n",
    "\n",
    "device = None\n",
    "if platform.system() == 'Windows':  # Check if the OS is Windows\n",
    "    import torch_directml  # Import torch_directml only on Windows\n",
    "    device = torch_directml.device()\n",
    "else:\n",
    "    !pip install -r requirements.txt\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.Trainer import Trainer\n",
    "from src.dataset.ImageDatasetPatch import ImageDatasetPatch\n",
    "from src.dataset.PatchImageTool import PatchImageTool\n",
    "\n",
    "from src.utils.PytorchUtil import PytorchUtil as torchUtil\n",
    "from src.utils.PlotUtils import PlotUtils\n",
    "\n",
    "from src.models.StatsManager import StatsManager\n",
    "\n",
    "from src.models.InitModel import InitModel\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import skimage.metrics as metrics\n",
    "# Import the platform module to detect the OS\n",
    "\n",
    "if not device:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 100 #10000\n",
    "\n",
    "LR = 0.0005\n",
    "BATCH_SIZE = 20\n",
    "PATCH_SIZE = 256\n",
    "\n",
    "UPSCALE_FACTORS = [2, 4, 8]\n",
    "\n",
    "TRAIN_SET = \"train_full_channel\"\n",
    "TEST_SET =  \"test_full_channel\"\n",
    "\n",
    "IMAGE_DIM = \"1920x1080\"\n",
    "\n",
    "CHANNELS = [\"b\", \"g\", \"r\", \"d\", \"s\"]\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "SMALL_DATASET_RANDOM_PATCH = False\n",
    "SMALL_DATASET_NUM_PATCH = 16\n",
    "\n",
    "PATH_SAVE_SMALL_MODEL = \"smallweights-upscale-residual2-lpips-v.3.1\"\n",
    "SMALL_MODEL_USE_LPIPS = \"lpips\" in PATH_SAVE_SMALL_MODEL\n",
    "\n",
    "EPOCH_SMALL_MODEL = 25\n",
    "\n",
    "DO_OVERFIT_MODEL = False\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "PATH_SAVE_MODEL = \"weights-upscale-residual2-lpips-v.3.1\"\n",
    "MODEL_USE_LPIPS = \"lpips\" in PATH_SAVE_MODEL\n",
    "\n",
    "EPOCH_MODEL = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEED:\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionStatsManager(StatsManager):\n",
    "    def __init__(self, upscaling_factor):\n",
    "        super(SuperResolutionStatsManager, self).__init__(upscaling_factor)\n",
    "\n",
    "    def init(self):\n",
    "        super(SuperResolutionStatsManager, self).init()\n",
    "        # Initializing `self.running_psnr`\n",
    "        self.metrics = ['psnr', 'ssim']\n",
    "\n",
    "        self.running_metrics = {}\n",
    "        for upscaling_factor in self.upscale_factor_list:\n",
    "            self.running_metrics[upscaling_factor] = {}\n",
    "\n",
    "            for metric in self.metrics:\n",
    "                self.running_metrics[upscaling_factor][metric] = 0\n",
    "\n",
    "    def accumulate(self, loss, x, y, d, upscale_factor):\n",
    "        super(SuperResolutionStatsManager, self).accumulate(loss, x, y, d, upscale_factor)\n",
    "        # Updating `self.running_psnr`\n",
    "        d_numpy = d.detach().to('cpu').numpy()\n",
    "        y_numpy = y.detach().to('cpu').numpy()\n",
    "\n",
    "        self.running_metrics[upscale_factor][\"psnr\"] += metrics.peak_signal_noise_ratio(d_numpy, y_numpy)\n",
    "\n",
    "        current_ssim = 0\n",
    "\n",
    "        for i in range(d_numpy.shape[0]):\n",
    "            d_numpy_temp = np.moveaxis(d_numpy[i], [0, 1, 2], [2, 0, 1])\n",
    "            y_numpy_temp = np.moveaxis(y_numpy[i], [0, 1, 2], [2, 0, 1])\n",
    "\n",
    "            value_range = max(d_numpy_temp.max(), y_numpy_temp.max()) - min(d_numpy_temp.min(), y_numpy_temp.min())\n",
    "            \n",
    "            current_ssim += metrics.structural_similarity(d_numpy_temp, y_numpy_temp, win_size=7, \n",
    "                                                          data_range=value_range, multichannel=True, \n",
    "                                                          channel_axis=2)\n",
    "        \n",
    "        self.running_metrics[upscale_factor][\"ssim\"] += current_ssim / d_numpy.shape[0]\n",
    "\n",
    "    def summarize(self):\n",
    "        losses : dict = super(SuperResolutionStatsManager, self).summarize()\n",
    "    \n",
    "        result = {}\n",
    "        for upscale_factor in self.upscale_factor_list:\n",
    "            result[upscale_factor] = {\n",
    "                \"loss\" : {},\n",
    "                \"metric\" : {}\n",
    "            }\n",
    "\n",
    "            # value / (self.number_update + 1e-9)\n",
    "            for key in self.metrics:\n",
    "                result[upscale_factor][\"metric\"][key] = self.running_metrics[upscale_factor][key] \\\n",
    "                                    / (self.number_update[upscale_factor] + 1e-9)\n",
    "            \n",
    "            for key in losses[upscale_factor].keys():\n",
    "                result[upscale_factor][\"loss\"][key] = losses[upscale_factor][key]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class Criterion:\n",
    "    def __init__(self, use_lpips=False) -> None:\n",
    "        self.use_lpips = use_lpips\n",
    "\n",
    "    def compute(self, y, d, lpips, lpips_lambda):\n",
    "        mse = F.mse_loss(y, d)\n",
    "        \n",
    "        if not self.use_lpips:\n",
    "            return {\n",
    "                \"loss\" : mse,\n",
    "                \"mse\" : mse,\n",
    "            }\n",
    "\n",
    "        lpips = lpips(y, d) * lpips_lambda\n",
    "        \n",
    "        return {\n",
    "            \"loss\" : mse + lpips,\n",
    "            \"mse\" : mse,\n",
    "            \"lpips\" : lpips\n",
    "        }\n",
    "\n",
    "    def itemize(self, loss):\n",
    "        cop = {}\n",
    "\n",
    "        for key in loss.keys():\n",
    "            if type(loss[key]) == torch.Tensor:\n",
    "                cop[key] = loss[key].item()\n",
    "            else:\n",
    "                cop[key] = loss[key]\n",
    "        \n",
    "        return cop\n",
    "\n",
    "    \"\"\"\n",
    "    Return only the sum loss\n",
    "    \"\"\"\n",
    "    def __call__(self, y, d, lpips, lpips_lambda):\n",
    "        return self.compute(y, d, lpips, lpips_lambda)[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_size = 256\n",
    "common_transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    common_transform,\n",
    "    #transforms.RandomRotation(degrees=10),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    #transforms.RandomResizedCrop(size=(new_img_size, new_img_size), scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    common_transform,\n",
    "    #transforms.CenterCrop((new_img_size, new_img_size)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset = ImageDatasetPatch(TRAIN_SET, IMAGE_DIM, UPSCALE_FACTORS, CHANNELS,\n",
    "                                        transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "full_test_dataset = ImageDatasetPatch(TEST_SET, IMAGE_DIM, UPSCALE_FACTORS, CHANNELS,\n",
    "                                      transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "train_dataset_patched = ImageDatasetPatch(TRAIN_SET, IMAGE_DIM, UPSCALE_FACTORS, CHANNELS,\n",
    "                                          transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "test_dataset_patched = ImageDatasetPatch(TEST_SET, IMAGE_DIM, UPSCALE_FACTORS, CHANNELS,\n",
    "                                          transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "full_train_dataset.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.show_dataset_example(full_train_dataset, num_images=4, plot_width=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "redirect all method of list to dataset\n",
    "\"\"\"\n",
    "class EncapsulatedDataset(list):\n",
    "    def __init__(self, dataset, upscale_factors, filter_channel_to_image_func):\n",
    "        self.dataset = dataset\n",
    "        self.upscale_factors = upscale_factors\n",
    "        self.filter_channel_to_image_func = filter_channel_to_image_func\n",
    "    \n",
    "    def number_upscale(self):\n",
    "        return len(self.upscale_factors)\n",
    "\n",
    "    def get_upscale_factor(self, index):\n",
    "        return self.upscale_factors[index]\n",
    "    \n",
    "    def filter_channels_to_image(self, channel):\n",
    "        return self.filter_channel_to_image_func(channel)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.__len__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset.__getitem__(index)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.dataset.__iter__()\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.dataset.__next__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.dataset.__str__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.dataset.__repr__()\n",
    "    \n",
    "    def __contains__(self, item):\n",
    "        return self.dataset.__contains__(item)\n",
    "    \n",
    "    def __reversed__(self):\n",
    "        return self.dataset.__reversed__()\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return self.dataset.__add__(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model on a small dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    if SMALL_DATASET_RANDOM_PATCH:\n",
    "        small_dataset = [train_dataset_patched[np.random.randint(len(train_dataset_patched))] for _ in range(SMALL_DATASET_NUM_PATCH)]\n",
    "    else:\n",
    "        small_dataset = [train_dataset_patched[i] for i in range(SMALL_DATASET_NUM_PATCH)]\n",
    "\n",
    "    small_train_size = int(0.8 * len(small_dataset))\n",
    "    small_valid_size = len(small_dataset) - small_train_size\n",
    "\n",
    "    # no random split\n",
    "    if SMALL_DATASET_RANDOM_PATCH:\n",
    "        small_train_dataset, small_valid_dataset = torchUtil.random_split(small_dataset, [small_train_size, small_valid_size])\n",
    "    else:\n",
    "        small_train_dataset = small_dataset[:small_train_size]\n",
    "        small_valid_dataset = small_dataset[small_train_size:]\n",
    "\n",
    "    small_train_dataset = EncapsulatedDataset(small_train_dataset, UPSCALE_FACTORS, train_dataset_patched.filter_channels_to_image)\n",
    "    small_valid_dataset = EncapsulatedDataset(small_valid_dataset, UPSCALE_FACTORS, test_dataset_patched.filter_channels_to_image)\n",
    "\n",
    "    print(\"Size of small_train_dataset:\", len(small_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      model_hyperparameters = {\n",
    "      \"channel_positions\" : CHANNELS,\n",
    "      \"channel_interpolations\" : [train_dataset_patched.get_channel_superresolution_method(channel) for channel in CHANNELS]\n",
    "      }\n",
    "      \n",
    "      r_small = InitModel.create_model(PATH_SAVE_SMALL_MODEL, model_hyperparameters, UPSCALE_FACTORS, device)\n",
    "\n",
    "      # In mega bytes\n",
    "      print(\"Size of model mb\", sum(p.numel() for p in r_small.parameters() if p.requires_grad) / (1024 * 1024))\n",
    "\n",
    "      # Size of batch in mega bytes\n",
    "      #print(\"Size of batch mb\", small_dataset[0][0].shape[0] * small_dataset[0][0].shape[1] \n",
    "            #* small_dataset[0][0].shape[2] * 4 / (1024 * 1024))\n",
    "\n",
    "      adam = torch.optim.Adam(r_small.parameters(), lr=LR)\n",
    "      stats_manager = SuperResolutionStatsManager(UPSCALE_FACTORS)\n",
    "\n",
    "      exp_small = Trainer(r_small, \n",
    "                        small_train_dataset, small_valid_dataset, \n",
    "                        adam, stats_manager, device, \n",
    "                        Criterion(use_lpips=SMALL_MODEL_USE_LPIPS)\n",
    "                        , batch_size=2,\n",
    "                        output_dir=PATH_SAVE_SMALL_MODEL, perform_validation_during_training=True, \n",
    "                        tensor_board=False, use_lpips_loss=SMALL_MODEL_USE_LPIPS)\n",
    "\n",
    "      # Show number of parameters\n",
    "      print(\"Number of parameters:\", sum(p.numel() for p in r_small.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    exp_small.run(num_epochs=EPOCH_SMALL_MODEL, plot=PlotUtils.plot_training_curve_and_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    PlotUtils.plot_images_from_model(exp_small, small_train_dataset, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    PlotUtils.plot_predicted_and_bicubic(exp_small, small_train_dataset, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model on a subsequent part of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the dataset size\n",
    "if len(train_dataset_patched) > SUBSET_SIZE:\n",
    "    train_dataset_patched.limit_dataset(SUBSET_SIZE)\n",
    "\n",
    "if len(test_dataset_patched) > SUBSET_SIZE * 0.2:\n",
    "    test_dataset_patched.limit_dataset(int(SUBSET_SIZE * 0.2))\n",
    "\n",
    "print(\"Size of sub train dataset\", len(train_dataset_patched))\n",
    "print(\"Size of sub test dataset\", len(test_dataset_patched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the sub part of the dataset from random indices\n",
    "train_size = int(0.8 * len(train_dataset_patched))\n",
    "valid_size = len(train_dataset_patched) - train_size\n",
    "\n",
    "train_sub_dataset, valid_sub_dataset = torch.utils.data.random_split(train_dataset_patched, [train_size, valid_size])\n",
    "\n",
    "train_sub_dataset = EncapsulatedDataset(train_sub_dataset, UPSCALE_FACTORS, train_dataset_patched.filter_channels_to_image)\n",
    "valid_sub_dataset = EncapsulatedDataset(valid_sub_dataset, UPSCALE_FACTORS, test_dataset_patched.filter_channels_to_image)\n",
    "\n",
    "print(\"Size of train_dataset: \", len(train_sub_dataset))\n",
    "print(\"Size of valid_dataset: \", len(valid_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_hyperparameters = {\n",
    "    \"channel_positions\" : CHANNELS,\n",
    "    \"channel_interpolations\" : [train_dataset_patched.get_channel_superresolution_method(channel) for channel in CHANNELS]\n",
    "}\n",
    "\n",
    "r = InitModel.create_model(PATH_SAVE_MODEL, model_hyperparameters, UPSCALE_FACTORS, device)\n",
    "\n",
    "# number of parameters\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in r.parameters() if p.requires_grad))\n",
    "\n",
    "adam = torch.optim.Adam(r.parameters(), lr=LR)\n",
    "stats_manager = SuperResolutionStatsManager(UPSCALE_FACTORS)\n",
    "\n",
    "exp = Trainer(r, \n",
    "                train_sub_dataset, valid_sub_dataset, \n",
    "                adam, stats_manager, device, \n",
    "                Criterion(use_lpips=MODEL_USE_LPIPS), \n",
    "                batch_size=BATCH_SIZE,\n",
    "                output_dir=PATH_SAVE_MODEL, perform_validation_during_training=True, \n",
    "                tensor_board=True, use_lpips_loss=MODEL_USE_LPIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(num_epochs=EPOCH_MODEL, plot=PlotUtils.plot_training_curve_and_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.plot_images_from_model(exp, train_dataset_patched, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.plot_predicted_and_bicubic(exp, train_dataset_patched, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct image from patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patch_index = np.random.randint(len(full_train_dataset))\n",
    "test_patch_index = np.random.randint(len(full_test_dataset))\n",
    "\n",
    "print(\"Choose index train\", train_patch_index, \"Choose index test\", test_patch_index)\n",
    "\n",
    "train_patch_start_index = full_train_dataset.get_index_start_patch(train_patch_index)\n",
    "test_patch_start_index = full_test_dataset.get_index_start_patch(test_patch_index)\n",
    "\n",
    "print (\"Start index patch train\", train_patch_start_index, \"Start index patch test\", test_patch_start_index)\n",
    "\n",
    "train_image_index = full_train_dataset.get_index_for_image(train_patch_index)\n",
    "test_image_index = full_test_dataset.get_index_for_image(test_patch_index)\n",
    "\n",
    "print (\"Index train\", train_image_index, \"Index test\", test_image_index)\n",
    "\n",
    "IMAGE_CHOSEN_UPSCALE_INDEX = 0\n",
    "\n",
    "train_lr_data_tensors, train_hr_img_tensor = full_train_dataset.get_full_image(train_image_index)\n",
    "test_lr_data_tensors, test_hr_img_tensor = full_test_dataset.get_full_image(test_image_index)\n",
    "\n",
    "train_lr_data_tensor = train_lr_data_tensors[IMAGE_CHOSEN_UPSCALE_INDEX]\n",
    "train_lr_img_tensor = full_train_dataset.filter_channels_to_image(train_lr_data_tensor)\n",
    "\n",
    "test_lr_data_tensor = test_lr_data_tensors[IMAGE_CHOSEN_UPSCALE_INDEX]\n",
    "test_lr_img_tensor = full_test_dataset.filter_channels_to_image(test_lr_data_tensor)\n",
    "\n",
    "hr_img_tensors = full_train_dataset.hr_data_size\n",
    "\n",
    "exp.net.set_upscale_mode(full_test_dataset.get_upscale_factor(IMAGE_CHOSEN_UPSCALE_INDEX))\n",
    "\n",
    "train_pred_img_tensor = PatchImageTool.predict_image_from_dataset_patches(exp, hr_img_tensors, full_train_dataset, train_patch_index, device)\n",
    "test_pred_img_tensor = PatchImageTool.predict_image_from_dataset_patches(exp, hr_img_tensors, full_test_dataset, test_patch_index, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.show_low_high_predicted([train_lr_img_tensor], [train_hr_img_tensor], [train_pred_img_tensor], plot_title=\"Train\")\n",
    "\n",
    "PlotUtils.show_low_high_predicted([test_lr_img_tensor], [test_hr_img_tensor], [test_pred_img_tensor], plot_title=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_img_np = torchUtil.tensor_to_numpy(train_pred_img_tensor)\n",
    "train_bicubic_img_np = torchUtil.resize_tensor_to_numpy(train_lr_img_tensor, \n",
    "                                                        (train_pred_img_np.shape[0], train_pred_img_np.shape[1]))\n",
    "\n",
    "train_subtraction_np = torchUtil.norm_numpy_image(train_pred_img_np - train_bicubic_img_np)\n",
    "\n",
    "PlotUtils.show_predicted_interpolated_subtraction([train_pred_img_np], [train_bicubic_img_np], [train_subtraction_np], \n",
    "                                                  plot_title=\"Train\")\n",
    "\n",
    "\n",
    "test_pred_img_np = torchUtil.tensor_to_numpy(test_pred_img_tensor)\n",
    "\n",
    "test_bicubic_img_np = torchUtil.resize_tensor_to_numpy(test_lr_img_tensor, \n",
    "                                                         (test_pred_img_np.shape[0], test_pred_img_np.shape[1]))\n",
    "\n",
    "\n",
    "test_subtraction_np = torchUtil.norm_numpy_image(test_pred_img_np - test_bicubic_img_np)\n",
    "\n",
    "PlotUtils.show_predicted_interpolated_subtraction([test_pred_img_np], [test_bicubic_img_np], [test_subtraction_np],\n",
    "                                                   plot_title=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PSNR and SSIM for the predicted image\n",
    "\n",
    "train_hr_img_np = torchUtil.tensor_to_numpy(train_hr_img_tensor)\n",
    "train_pred_img_np = torchUtil.tensor_to_numpy(train_pred_img_tensor)\n",
    "\n",
    "train_psnr = metrics.peak_signal_noise_ratio(train_hr_img_np, train_pred_img_np)\n",
    "train_ssim = metrics.structural_similarity(train_hr_img_np, train_pred_img_np,\n",
    "                                            win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "test_hr_img_np = torchUtil.tensor_to_numpy(test_hr_img_tensor)\n",
    "test_pred_img_np = torchUtil.tensor_to_numpy(test_pred_img_tensor)\n",
    "\n",
    "test_psnr = metrics.peak_signal_noise_ratio(test_hr_img_np, test_pred_img_np)\n",
    "test_ssim = metrics.structural_similarity(test_hr_img_np, test_pred_img_np, \n",
    "                                          win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "print(\"Train PSNR\", train_psnr, \"Train SSIM\", train_ssim)\n",
    "print(\"Test PSNR\", test_psnr, \"Test SSIM\", test_ssim)\n",
    "\n",
    "# Compute the PSNR and SSIM for the bilinear image\n",
    "\n",
    "train_bicubic_psnr = metrics.peak_signal_noise_ratio(train_hr_img_np, train_bicubic_img_np)\n",
    "train_bicubic_ssim = metrics.structural_similarity(train_hr_img_np, train_bicubic_img_np, win_size=7, \n",
    "                                                   data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "test_bicubic_psnr = metrics.peak_signal_noise_ratio(test_hr_img_np, test_bicubic_img_np)\n",
    "test_bicubic_ssim = metrics.structural_similarity(test_hr_img_np, test_bicubic_img_np, win_size=7,\n",
    "                                                   data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "print()\n",
    "print(\"Train bicubic PSNR\", train_bicubic_psnr, \"Train bicubic SSIM\", train_bicubic_ssim)\n",
    "print(\"Test bicubic PSNR\", test_bicubic_psnr, \"Test bicubic SSIM\", test_bicubic_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on 20 images from the test set\n",
    "sub_dataset_size = 20\n",
    "indices = np.random.choice(len(full_test_dataset), sub_dataset_size, replace=False)\n",
    "pred_img_tensors = PatchImageTool.predict_images_from_dataset_patches(exp, (1920, 1080), full_test_dataset, indices, device, \n",
    "                                                                      batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 4 images, real vs predicted\n",
    "\n",
    "lr_img_tensors = []\n",
    "hr_img_tensors = []\n",
    "\n",
    "for i in range(4):\n",
    "    index = indices[i]\n",
    "    image_index = full_test_dataset.get_index_for_image(index)\n",
    "\n",
    "    lr_data_tensors, hr_img_tensor = full_test_dataset.get_full_image(image_index)\n",
    "    lr_data_tensor = lr_data_tensors[IMAGE_CHOSEN_UPSCALE_INDEX]\n",
    "\n",
    "    lr_img_tensors.append(train_dataset_patched.filter_channels_to_image(lr_data_tensor))\n",
    "    hr_img_tensors.append(hr_img_tensor)\n",
    "\n",
    "PlotUtils.show_low_high_predicted(lr_img_tensors, hr_img_tensors, pred_img_tensors[:len(lr_img_tensors)], plot_title=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 4 images, predicted, bilinear and subtraction\n",
    "\n",
    "pred_img_nps = []\n",
    "bicubic_img_nps = []\n",
    "subtraction_img_nps = []\n",
    "\n",
    "for i in range(4):\n",
    "    index = indices[i]\n",
    "    image_index = full_test_dataset.get_index_for_image(index)\n",
    "\n",
    "    lr_data_tensors, hr_img_tensor = full_test_dataset.get_full_image(image_index)\n",
    "    lr_data_tensor = lr_data_tensors[IMAGE_CHOSEN_UPSCALE_INDEX]\n",
    "\n",
    "    lr_img_tensor = train_dataset_patched.filter_channels_to_image(lr_data_tensor)\n",
    "\n",
    "    pred_img_np = torchUtil.tensor_to_numpy(pred_img_tensors[i])\n",
    "    bicubic_img_np = torchUtil.resize_tensor_to_numpy(lr_img_tensor, (pred_img_np.shape[0], pred_img_np.shape[1]))\n",
    "\n",
    "    pred_img_nps.append(pred_img_np)\n",
    "    bicubic_img_nps.append(bicubic_img_np)\n",
    "    \n",
    "    subtraction_img_np = torchUtil.norm_numpy_image(pred_img_np - bicubic_img_np)\n",
    "    subtraction_img_nps.append(subtraction_img_np)\n",
    "\n",
    "PlotUtils.show_predicted_interpolated_subtraction(pred_img_nps, bicubic_img_nps, subtraction_img_nps, \n",
    "                                                  plot_title=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean and var psnr and ssim for n images from the test set\n",
    "\n",
    "batch_size = full_test_dataset.get_number_patch_per_image(upscale_index=IMAGE_CHOSEN_UPSCALE_INDEX) * 4\n",
    "\n",
    "sub_size_factor = 1\n",
    "sub_dataset_size = int(sub_size_factor * len(full_test_dataset) / full_test_dataset.get_number_patch_per_image(upscale_index=IMAGE_CHOSEN_UPSCALE_INDEX))\n",
    "print(\"Number of images in full data set part\", sub_dataset_size)\n",
    "test_psnr, test_ssim = PatchImageTool.compute_metrics_dataset_batched(exp, (1920, 1080), full_test_dataset, sub_dataset_size, device, batch_size)\n",
    "\n",
    "# Compute the PSNR and SSIM for the bilinear image on a subset of the train set\n",
    "\n",
    "test_bicubic_psnr, test_bicubic_ssim = [], []\n",
    "\n",
    "for i in range(sub_dataset_size):\n",
    "    lr_data_tensors, hr_img_tensor = full_test_dataset.get_full_image(i)\n",
    "\n",
    "    lr_data_tensor = lr_data_tensors[IMAGE_CHOSEN_UPSCALE_INDEX]\n",
    "    lr_img_tensor = full_test_dataset.filter_channels_to_image(lr_data_tensor)\n",
    "\n",
    "    hr_img_np = torchUtil.tensor_to_numpy(hr_img_tensor)\n",
    "\n",
    "    bicubic_img_np = torchUtil.resize_tensor_to_numpy(lr_img_tensor, (hr_img_np.shape[0], hr_img_np.shape[1]))\n",
    "\n",
    "    test_bicubic_psnr.append(metrics.peak_signal_noise_ratio(hr_img_np, bicubic_img_np))\n",
    "    test_bicubic_ssim.append(metrics.structural_similarity(hr_img_np, bicubic_img_np, \n",
    "                                                            win_size=7, data_range=1,\n",
    "                                                            multichannel=True, channel_axis=2))\n",
    "\n",
    "# compute the mean and var psnr and ssim for 100 images from the train set\n",
    "\n",
    "print(\"Average PSNR for test images\", test_psnr.mean(), \"Variance\", test_psnr.var())\n",
    "print(\"Average SSIM for test images\", test_ssim.mean(), \"Variance\", test_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for bicubic test images\", np.array(test_bicubic_psnr).mean(), \"Variance\", np.array(test_bicubic_psnr).var())\n",
    "print(\"Average SSIM for bicubic test images\", np.array(test_bicubic_ssim).mean(), \"Variance\", np.array(test_bicubic_ssim).var())\n",
    "\n",
    "print()\n",
    "\n",
    "sub_dataset_size = int(sub_size_factor * len(full_train_dataset) / full_train_dataset.get_number_patch_per_image(upscale_index=IMAGE_CHOSEN_UPSCALE_INDEX))\n",
    "print(\"Number of images in full data set part\", sub_dataset_size)\n",
    "train_psnr, train_ssim = PatchImageTool.compute_metrics_dataset_batched(exp,  (1920, 1080), \n",
    "                                                                        full_train_dataset, sub_dataset_size, device, batch_size)\n",
    "\n",
    "train_bicubic_psnr, train_bicubic_ssim = [], []\n",
    "\n",
    "for i in range(sub_dataset_size):\n",
    "    lr_data_tensors, hr_img_tensor = full_train_dataset.get_full_image(i)\n",
    "\n",
    "    lr_data_tensor = lr_data_tensors[IMAGE_CHOSEN_UPSCALE_INDEX]\n",
    "    lr_img_tensor = full_train_dataset.filter_channels_to_image(lr_data_tensor)\n",
    "\n",
    "    hr_img_np = torchUtil.tensor_to_numpy(hr_img_tensor)\n",
    "\n",
    "    bicubic_img_np = torchUtil.resize_tensor_to_numpy(lr_img_tensor, (hr_img_np.shape[0], hr_img_np.shape[1]))\n",
    "\n",
    "    train_bicubic_psnr.append(metrics.peak_signal_noise_ratio(hr_img_np, bicubic_img_np, ))\n",
    "    train_bicubic_ssim.append(metrics.structural_similarity(hr_img_np, bicubic_img_np, \n",
    "                                                            win_size=7, data_range=1,\n",
    "                                                            multichannel=True, channel_axis=2))\n",
    "\n",
    "print(\"=========================================\")\n",
    "\n",
    "print(\"Average PSNR for test images\", test_psnr.mean(), \"Variance\", test_psnr.var())\n",
    "print(\"Average SSIM for test images\", test_ssim.mean(), \"Variance\", test_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for bicubic test images\", np.array(test_bicubic_psnr).mean(), \"Variance\", np.array(test_bicubic_psnr).var())\n",
    "print(\"Average SSIM for bicubic test images\", np.array(test_bicubic_ssim).mean(), \"Variance\", np.array(test_bicubic_ssim).var())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Average PSNR for train images\", train_psnr.mean(), \"Variance\", train_psnr.var())\n",
    "print(\"Average SSIM for train images\", train_ssim.mean(), \"Variance\", train_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for bicubic train images\", np.array(train_bicubic_psnr).mean(), \"Variance\", np.array(train_bicubic_psnr).var())\n",
    "print(\"Average SSIM for bicubic train images\", np.array(train_bicubic_ssim).mean(), \"Variance\", np.array(train_bicubic_ssim).var())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
