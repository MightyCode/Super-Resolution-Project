{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training file for any model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: opencv-python in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.8.1.78)\n",
      "Requirement already satisfied: matplotlib in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.7.3)\n",
      "Requirement already satisfied: torch in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.16.0)\n",
      "Requirement already satisfied: torchmetrics in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: ipykernel in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (6.26.0)\n",
      "Requirement already satisfied: tqdm in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.66.1)\n",
      "Requirement already satisfied: scikit-image in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.22.0)\n",
      "Requirement already satisfied: gdown in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (4.7.1)\n",
      "Requirement already satisfied: scikit-learn in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.1.3)\n",
      "Requirement already satisfied: tensorboard in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.14.1)\n",
      "Requirement already satisfied: streamlit in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.29.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: filelock in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (3.2)\n",
      "Requirement already satisfied: jinja2 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 4)) (12.3.52)\n",
      "Requirement already satisfied: requests in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 5)) (2.31.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from torchmetrics->-r requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (8.17.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (5.9.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 7)) (5.13.0)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 9)) (1.11.3)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 9)) (2.31.6)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 9)) (2023.9.26)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 9)) (0.3)\n",
      "Requirement already satisfied: six in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 10)) (4.12.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 11)) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (3.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (4.24.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 12)) (3.0.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (6.11.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (1.5.2)\n",
      "Requirement already satisfied: pyarrow>=6.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (14.0.1)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (13.7.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (0.10.2)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (3.1.40)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (0.8.1b0)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from streamlit->-r requirements.txt (line 13)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 13)) (4.19.2)\n",
      "Requirement already satisfied: toolz in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 13)) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 13)) (4.0.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 12)) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit->-r requirements.txt (line 13)) (3.17.0)\n",
      "Requirement already satisfied: decorator in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (4.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 13)) (2023.3.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 5)) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 13)) (3.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from beautifulsoup4->gdown->-r requirements.txt (line 10)) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from requests[socks]->gdown->-r requirements.txt (line 10)) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 13)) (5.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 13)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 13)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 13)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 13)) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.10)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 12)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 12)) (3.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/maxence/miniconda3/envs/tf/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "import platform \n",
    "\n",
    "\n",
    "device = None\n",
    "if platform.system() == 'Windows':  # Check if the OS is Windows\n",
    "    import torch_directml  # Import torch_directml only on Windows\n",
    "    device = torch_directml.device()\n",
    "else:\n",
    "    !pip install -r requirements.txt\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 14:29:46.225713: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-16 14:29:46.251148: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-16 14:29:46.251172: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-16 14:29:46.251189: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 14:29:46.256001: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models.Trainer import Trainer\n",
    "from src.dataset.ImageDatasetPatch import ImageDatasetPatch\n",
    "from src.dataset.PatchImageTool import PatchImageTool\n",
    "\n",
    "from src.utils.PytorchUtil import PytorchUtil as torchUtil\n",
    "from src.utils.PlotUtils import PlotUtils\n",
    "\n",
    "from src.models.StatsManager import StatsManager\n",
    "\n",
    "from src.models.InitModel import InitModel\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import skimage.metrics as metrics\n",
    "# Import the platform module to detect the OS\n",
    "\n",
    "if not device:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 10000\n",
    "\n",
    "LR = 0.0005\n",
    "BATCH_SIZE = 20\n",
    "PATCH_SIZE = 256\n",
    "\n",
    "UPSCALE_FACTORS = [2, 4, 8]\n",
    "\n",
    "TRAIN_SET = \"train_full_channel\"\n",
    "TEST_SET = \"test_full_channel\"\n",
    "\n",
    "IMAGE_DIM = \"1920x1080\"\n",
    "\n",
    "CHANNELS = [\"r\", \"g\", \"b\"]\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "PATH_SAVE_SMALL_MODEL = \"smallweights-upscale-residual-lpips-v.1\"\n",
    "SMALL_MODEL_USE_LPIPS = \"lpips\" in PATH_SAVE_SMALL_MODEL\n",
    "\n",
    "EPOCH_SMALL_MODEL = 2\n",
    "\n",
    "DO_OVERFIT_MODEL = False\n",
    "\n",
    "# ------------------------------------------\n",
    "\n",
    "PATH_SAVE_MODEL = \"weights-upscale-lpips-v.2.2\"\n",
    "MODEL_USE_LPIPS = \"lpips\" in PATH_SAVE_MODEL\n",
    "\n",
    "EPOCH_MODEL = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionStatsManager(StatsManager):\n",
    "    def __init__(self, upscaling_factor):\n",
    "        super(SuperResolutionStatsManager, self).__init__(upscaling_factor)\n",
    "\n",
    "    def init(self):\n",
    "        super(SuperResolutionStatsManager, self).init()\n",
    "        # Initializing `self.running_psnr`\n",
    "        self.metrics = ['psnr', 'ssim']\n",
    "\n",
    "        self.running_metrics = {}\n",
    "        for upscaling_factor in self.upscale_factor_list:\n",
    "            self.running_metrics[upscaling_factor] = {}\n",
    "\n",
    "            for metric in self.metrics:\n",
    "                self.running_metrics[upscaling_factor][metric] = 0\n",
    "\n",
    "    def accumulate(self, loss, x, y, d, upscale_factor):\n",
    "        super(SuperResolutionStatsManager, self).accumulate(loss, x, y, d, upscale_factor)\n",
    "        # Updating `self.running_psnr`\n",
    "        d_numpy = d.detach().to('cpu').numpy()\n",
    "        y_numpy = y.detach().to('cpu').numpy()\n",
    "\n",
    "        self.running_metrics[upscale_factor][\"psnr\"] += metrics.peak_signal_noise_ratio(d_numpy, y_numpy)\n",
    "\n",
    "        current_ssim = 0\n",
    "\n",
    "        for i in range(d_numpy.shape[0]):\n",
    "            d_numpy_temp = np.moveaxis(d_numpy[i], [0, 1, 2], [2, 0, 1])\n",
    "            y_numpy_temp = np.moveaxis(y_numpy[i], [0, 1, 2], [2, 0, 1])\n",
    "\n",
    "            value_range = max(d_numpy_temp.max(), y_numpy_temp.max()) - min(d_numpy_temp.min(), y_numpy_temp.min())\n",
    "            \n",
    "            current_ssim += metrics.structural_similarity(d_numpy_temp, y_numpy_temp, win_size=7, \n",
    "                                                          data_range=value_range, multichannel=True, \n",
    "                                                          channel_axis=2)\n",
    "        \n",
    "        self.running_metrics[upscale_factor][\"ssim\"] += current_ssim / d_numpy.shape[0]\n",
    "\n",
    "    def summarize(self):\n",
    "        losses : dict = super(SuperResolutionStatsManager, self).summarize()\n",
    "    \n",
    "        result = {}\n",
    "        for upscale_factor in self.upscale_factor_list:\n",
    "            result[upscale_factor] = {\n",
    "                \"loss\" : {},\n",
    "                \"metric\" : {}\n",
    "            }\n",
    "\n",
    "            # value / (self.number_update + 1e-9)\n",
    "            for key in self.metrics:\n",
    "                result[upscale_factor][\"metric\"][key] = self.running_metrics[upscale_factor][key] \\\n",
    "                                    / (self.number_update[upscale_factor] + 1e-9)\n",
    "            \n",
    "            for key in losses[upscale_factor].keys():\n",
    "                result[upscale_factor][\"loss\"][key] = losses[upscale_factor][key]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class Criterion:\n",
    "    def __init__(self, use_lpips=False) -> None:\n",
    "        self.use_lpips = use_lpips\n",
    "\n",
    "    def compute(self, y, d, lpips, lpips_lambda):\n",
    "        mse = F.mse_loss(y, d)\n",
    "        \n",
    "        if not self.use_lpips:\n",
    "            return {\n",
    "                \"loss\" : mse,\n",
    "                \"mse\" : mse,\n",
    "            }\n",
    "\n",
    "        lpips = lpips(y, d) * lpips_lambda\n",
    "        \n",
    "        return {\n",
    "            \"loss\" : mse + lpips,\n",
    "            \"mse\" : mse,\n",
    "            \"lpips\" : lpips\n",
    "        }\n",
    "\n",
    "    def itemize(self, loss):\n",
    "        cop = {}\n",
    "\n",
    "        for key in loss.keys():\n",
    "            if type(loss[key]) == torch.Tensor:\n",
    "                cop[key] = loss[key].item()\n",
    "            else:\n",
    "                cop[key] = loss[key]\n",
    "        \n",
    "        return cop\n",
    "\n",
    "    \"\"\"\n",
    "    Return only the sum loss\n",
    "    \"\"\"\n",
    "    def __call__(self, y, d, lpips, lpips_lambda):\n",
    "        return self.compute(y, d, lpips, lpips_lambda)[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_size = 256\n",
    "common_transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    common_transform,\n",
    "    #transforms.RandomRotation(degrees=10),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    #transforms.RandomResizedCrop(size=(new_img_size, new_img_size), scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    common_transform,\n",
    "    #transforms.CenterCrop((new_img_size, new_img_size)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for download and resize ...\n",
      "Low-res 960x540 dataset not present, resizing it ...\n",
      "Resizing images...\n",
      "(1080, 1920, 5)\n",
      "resources/train_full_channel/960x540/159.npy\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m full_train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mImageDatasetPatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_SET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMAGE_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUPSCALE_FACTORS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m full_test_dataset \u001b[38;5;241m=\u001b[39m ImageDatasetPatch(TEST_SET, IMAGE_DIM, UPSCALE_FACTORS, \n\u001b[1;32m      5\u001b[0m                                       transforms\u001b[38;5;241m=\u001b[39mtrain_transform, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, patch_size\u001b[38;5;241m=\u001b[39mPATCH_SIZE)\n\u001b[1;32m      7\u001b[0m train_dataset_patched \u001b[38;5;241m=\u001b[39m ImageDatasetPatch(TRAIN_SET, IMAGE_DIM, UPSCALE_FACTORS, \n\u001b[1;32m      8\u001b[0m                                           transforms\u001b[38;5;241m=\u001b[39mtrain_transform, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, patch_size\u001b[38;5;241m=\u001b[39mPATCH_SIZE)\n",
      "File \u001b[0;32m~/Super-Resolution-Project/src/dataset/ImageDatasetPatch.py:18\u001b[0m, in \u001b[0;36mImageDatasetPatch.__init__\u001b[0;34m(self, dataset_name, high_res, upscale_factors, transforms, download, patch_size, verbose)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     11\u001b[0m              dataset_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m              high_res:\u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1920x1080\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m              patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m     17\u001b[0m              verbose:\u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupscale_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_sizes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upscale_factor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupscale_factors:\n",
      "File \u001b[0;32m~/Super-Resolution-Project/src/dataset/ImageDataset.py:68\u001b[0m, in \u001b[0;36mImageDataset.__init__\u001b[0;34m(self, dataset_name, high_res, upscale_factors, transforms, download, verbose)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     66\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLow-res \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_res_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset not present, resizing it ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhigh_res_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh_res_path)\n",
      "File \u001b[0;32m~/Super-Resolution-Project/src/dataset/ImageDataset.py:153\u001b[0m, in \u001b[0;36mImageDataset.resize_dataset\u001b[0;34m(self, source, index_upscale)\u001b[0m\n\u001b[1;32m    151\u001b[0m source_img \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source, img)\n\u001b[1;32m    152\u001b[0m dest_img \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_dest, img)\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_res_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Super-Resolution-Project/src/dataset/ImageDataset.py:174\u001b[0m, in \u001b[0;36mImageDataset.resize_image\u001b[0;34m(self, source, dest, new_res_size)\u001b[0m\n\u001b[1;32m    171\u001b[0m     result[:, :, i] \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img[:, :, i], new_res_size)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mprint\u001b[39m(dest)\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_image(dest, result)\n",
      "\u001b[0;31mException\u001b[0m: Stop"
     ]
    }
   ],
   "source": [
    "full_train_dataset = ImageDatasetPatch(TRAIN_SET, IMAGE_DIM, UPSCALE_FACTORS,\n",
    "                                        transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "full_test_dataset = ImageDatasetPatch(TEST_SET, IMAGE_DIM, UPSCALE_FACTORS, \n",
    "                                      transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "train_dataset_patched = ImageDatasetPatch(TRAIN_SET, IMAGE_DIM, UPSCALE_FACTORS, \n",
    "                                          transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "test_dataset_patched = ImageDatasetPatch(TEST_SET, IMAGE_DIM, UPSCALE_FACTORS,\n",
    "                                          transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "full_train_dataset.print_info()\n",
    "\n",
    "if len(train_dataset_patched) > SUBSET_SIZE:\n",
    "    train_dataset_patched.limit_dataset(SUBSET_SIZE)\n",
    "\n",
    "if len(test_dataset_patched) > SUBSET_SIZE * 0.2:\n",
    "    test_dataset_patched.limit_dataset(int(SUBSET_SIZE * 0.2))\n",
    "\n",
    "print(\"Size of sub train dataset\", len(train_dataset_patched))\n",
    "print(\"Size of sub test dataset\", len(test_dataset_patched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mPlotUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_dataset_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Super-Resolution-Project/src/utils/PlotUtils.py:62\u001b[0m, in \u001b[0;36mPlotUtils.show_dataset_example\u001b[0;34m(dataset, num_images, indices, width)\u001b[0m\n\u001b[1;32m     60\u001b[0m     upscale_factors\u001b[38;5;241m.\u001b[39mappend(dataset\u001b[38;5;241m.\u001b[39mget_upscale_factor(index_low_res_patch))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     low_res_patches, high_res \u001b[38;5;241m=\u001b[39m dataset[index]\n\u001b[1;32m     65\u001b[0m     index_low_res_patch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mlen\u001b[39m(low_res_patches))\n",
      "File \u001b[0;32mmtrand.pyx:781\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_bounded_integers.pyx:1334\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: high <= 0"
     ]
    }
   ],
   "source": [
    "PlotUtils.show_dataset_example(full_train_dataset, num_images=3, width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "redirect all method of list to dataset\n",
    "\"\"\"\n",
    "class EncapsulatedDataset(list):\n",
    "    def __init__(self, dataset, upscale_factors):\n",
    "        self.dataset = dataset\n",
    "        self.upscale_factors = upscale_factors\n",
    "    \n",
    "    def number_upscale(self):\n",
    "        return len(self.upscale_factors)\n",
    "\n",
    "    def get_upscale_factor(self, index):\n",
    "        return self.upscale_factors[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.__len__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset.__getitem__(index)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.dataset.__iter__()\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.dataset.__next__()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.dataset.__str__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.dataset.__repr__()\n",
    "    \n",
    "    def __contains__(self, item):\n",
    "        return self.dataset.__contains__(item)\n",
    "    \n",
    "    def __reversed__(self):\n",
    "        return self.dataset.__reversed__()\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return self.dataset.__add__(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model on a small dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    small_dataset_size = 30\n",
    "    small_dataset = [train_dataset_patched[np.random.randint(len(train_dataset_patched))] for _ in range(small_dataset_size)]\n",
    "\n",
    "    small_train_size = int(0.8 * len(small_dataset))\n",
    "    small_valid_size = len(small_dataset) - small_train_size\n",
    "    small_train_dataset, small_valid_dataset = torch.utils.data.random_split(small_dataset, [small_train_size, small_valid_size])\n",
    "\n",
    "    small_train_dataset = EncapsulatedDataset(small_train_dataset, UPSCALE_FACTORS)\n",
    "    small_valid_dataset = EncapsulatedDataset(small_valid_dataset, UPSCALE_FACTORS)\n",
    "\n",
    "    print(\"Size of small_train_dataset:\", len(small_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "      r_small = InitModel.create_model(PATH_SAVE_SMALL_MODEL, {}, UPSCALE_FACTORS, device)\n",
    "\n",
    "      # In mega bytes\n",
    "      print(\"Size of model mb\", sum(p.numel() for p in r_small.parameters() if p.requires_grad) / (1024 * 1024))\n",
    "\n",
    "      # Size of batch in mega bytes\n",
    "      #print(\"Size of batch mb\", small_dataset[0][0].shape[0] * small_dataset[0][0].shape[1] \n",
    "            #* small_dataset[0][0].shape[2] * 4 / (1024 * 1024))\n",
    "\n",
    "      adam = torch.optim.Adam(r_small.parameters(), lr=LR)\n",
    "      stats_manager = SuperResolutionStatsManager(UPSCALE_FACTORS)\n",
    "\n",
    "      exp_small = Trainer(r_small, \n",
    "                        small_train_dataset, small_valid_dataset, \n",
    "                        adam, stats_manager, device, \n",
    "                        Criterion(use_lpips=SMALL_MODEL_USE_LPIPS)\n",
    "                        , batch_size=2,\n",
    "                        output_dir=PATH_SAVE_SMALL_MODEL, perform_validation_during_training=True, \n",
    "                        tensor_board=False, use_lpips_loss=SMALL_MODEL_USE_LPIPS)\n",
    "\n",
    "      # Show number of parameters\n",
    "      print(\"Number of parameters:\", sum(p.numel() for p in r_small.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    exp_small.run(num_epochs=EPOCH_SMALL_MODEL, plot=PlotUtils.plot_training_curve_and_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    PlotUtils.plot_images_from_model(exp_small, small_train_dataset, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFIT_MODEL:\n",
    "    PlotUtils.plot_predicted_and_bicubic(exp_small, small_train_dataset, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model on a subsequent part of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the sub part of the dataset from random indices\n",
    "train_size = int(0.8 * len(train_dataset_patched))\n",
    "valid_size = len(train_dataset_patched) - train_size\n",
    "\n",
    "train_sub_dataset, valid_sub_dataset = torch.utils.data.random_split(train_dataset_patched, [train_size, valid_size])\n",
    "\n",
    "train_sub_dataset = EncapsulatedDataset(train_sub_dataset, UPSCALE_FACTORS)\n",
    "valid_sub_dataset = EncapsulatedDataset(valid_sub_dataset, UPSCALE_FACTORS)\n",
    "\n",
    "print(\"Size of train_dataset: \", len(train_sub_dataset))\n",
    "print(\"Size of valid_dataset: \", len(valid_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "r = InitModel.create_model(PATH_SAVE_MODEL, {}, UPSCALE_FACTORS, device)\n",
    "\n",
    "# number of parameters\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in r.parameters() if p.requires_grad))\n",
    "\n",
    "adam = torch.optim.Adam(r.parameters(), lr=LR)\n",
    "stats_manager = SuperResolutionStatsManager(UPSCALE_FACTORS)\n",
    "\n",
    "exp = Trainer(r, \n",
    "                train_sub_dataset, valid_sub_dataset, \n",
    "                adam, stats_manager, device, \n",
    "                Criterion(use_lpips=MODEL_USE_LPIPS), \n",
    "                batch_size=BATCH_SIZE,\n",
    "                output_dir=PATH_SAVE_MODEL, perform_validation_during_training=True, \n",
    "                tensor_board=True, use_lpips_loss=MODEL_USE_LPIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.run(num_epochs=EPOCH_MODEL, plot=PlotUtils.plot_training_curve_and_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.plot_images_from_model(exp, test_dataset_patched, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.plot_predicted_and_bicubic(exp, test_dataset_patched, device, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct image from patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_patch_train = np.random.randint(len(full_train_dataset))\n",
    "index_patch_test = np.random.randint(len(full_test_dataset))\n",
    "\n",
    "print(\"Choose index train\", index_patch_train, \"Choose index test\", index_patch_test)\n",
    "\n",
    "start_index_patch_train = full_train_dataset.get_index_start_patch(index_patch_train)\n",
    "start_index_patch_test = full_test_dataset.get_index_start_patch(index_patch_test)\n",
    "\n",
    "print (\"Start index patch train\", start_index_patch_train, \"Start index patch test\", start_index_patch_test)\n",
    "\n",
    "index_train = full_train_dataset.get_index_for_image(index_patch_train)\n",
    "index_test = full_test_dataset.get_index_for_image(index_patch_test)\n",
    "\n",
    "print (\"Index train\", index_train, \"Index test\", index_test)\n",
    "\n",
    "chosen_upscale = 0\n",
    "\n",
    "train_low_res_images, train_high_res = full_train_dataset.get_full_image(index_train)\n",
    "test_low_res_images, test_high_res = full_test_dataset.get_full_image(index_test)\n",
    "\n",
    "train_low_res = train_low_res_images[chosen_upscale]\n",
    "test_low_res = test_low_res_images[chosen_upscale]\n",
    "\n",
    "high_res = full_train_dataset.high_res_size\n",
    "\n",
    "exp.net.set_upscale_mode(full_test_dataset.get_upscale_factor(chosen_upscale))\n",
    "pred_high_res1 = PatchImageTool.predict_image_from_dataset_patches(exp, high_res, full_train_dataset, index_patch_train, device)\n",
    "pred_high_res2 = PatchImageTool.predict_image_from_dataset_patches(exp, high_res, full_test_dataset, index_patch_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotUtils.show_low_high_predicted([train_low_res], [train_high_res], [pred_high_res1], name=\"Train\")\n",
    "\n",
    "PlotUtils.show_low_high_predicted([test_low_res], [test_high_res], [pred_high_res2], name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_high_res1_numpy = torchUtil.tensor_to_numpy(pred_high_res1)\n",
    "bicubic_image1_numpy = torchUtil.resize_tensor_to_numpy(\n",
    "    train_low_res, (pred_high_res1_numpy.shape[0], pred_high_res1_numpy.shape[1]))\n",
    "\n",
    "subtraction_numpy = torchUtil.norm_numpy_image(pred_high_res1_numpy - bicubic_image1_numpy)\n",
    "\n",
    "PlotUtils.show_predicted_interpolated_subtraction([pred_high_res1_numpy], [bicubic_image1_numpy], [subtraction_numpy], \n",
    "                                                  name=\"Train\")\n",
    "\n",
    "pred_high_res2_numpy = torchUtil.tensor_to_numpy(pred_high_res2)\n",
    "\n",
    "bicubic_image2_numpy = torchUtil.resize_tensor_to_numpy(test_low_res, \n",
    "                                                         (pred_high_res2_numpy.shape[0], \n",
    "                                                          pred_high_res2_numpy.shape[1]))\n",
    "\n",
    "\n",
    "subtraction2_numpy = torchUtil.norm_numpy_image(pred_high_res2_numpy - bicubic_image2_numpy)\n",
    "\n",
    "PlotUtils.show_predicted_interpolated_subtraction([pred_high_res2_numpy], [bicubic_image2_numpy], [subtraction2_numpy],\n",
    "                                                   name=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PSNR and SSIM for the predicted image\n",
    "\n",
    "train_high_res_np = torchUtil.tensor_to_numpy(train_high_res)\n",
    "test_high_res_np = torchUtil.tensor_to_numpy(test_high_res)\n",
    "\n",
    "pred_high_res1_np = torchUtil.tensor_to_numpy(pred_high_res1)\n",
    "pred_high_res2_np = torchUtil.tensor_to_numpy(pred_high_res2)\n",
    "\n",
    "train_psnr = metrics.peak_signal_noise_ratio(train_high_res_np, pred_high_res1_np)\n",
    "train_ssim = metrics.structural_similarity(train_high_res_np, pred_high_res1_np,\n",
    "                                            win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "test_psnr = metrics.peak_signal_noise_ratio(test_high_res_np, pred_high_res2_np)\n",
    "test_ssim = metrics.structural_similarity(test_high_res_np, pred_high_res2_np, \n",
    "                                          win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "print(\"Train PSNR\", train_psnr, \"Train SSIM\", train_ssim)\n",
    "print(\"Test PSNR\", test_psnr, \"Test SSIM\", test_ssim)\n",
    "\n",
    "# Compute the PSNR and SSIM for the bilinear image\n",
    "\n",
    "train_bicubic_psnr = metrics.peak_signal_noise_ratio(train_high_res_np, bicubic_image1_numpy)\n",
    "train_bicubic_ssim = metrics.structural_similarity(train_high_res_np, bicubic_image1_numpy, win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "test_bicubic_psnr = metrics.peak_signal_noise_ratio(test_high_res_np, bicubic_image2_numpy)\n",
    "test_bicubic_ssim = metrics.structural_similarity(test_high_res_np, bicubic_image2_numpy, win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "print()\n",
    "print(\"Train bicubic PSNR\", train_bicubic_psnr, \"Train bicubic SSIM\", train_bicubic_ssim)\n",
    "print(\"Test bicubic PSNR\", test_bicubic_psnr, \"Test bicubic SSIM\", test_bicubic_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset_size = 10\n",
    "\n",
    "# Compute the PSNR and SSIM for the predicted image on a subset of the train set\n",
    "train_psnr, train_ssim = PatchImageTool.compute_metrics_dataset(exp, full_train_dataset, sub_dataset_size, (1920, 1080), device)\n",
    "\n",
    "# Compute the PSNR and SSIM for the predicted image on a subset of the test set\n",
    "test_psnr, test_ssim = PatchImageTool.compute_metrics_dataset(exp, full_test_dataset, sub_dataset_size, (1920, 1080), device)\n",
    "\n",
    "print()\n",
    "print(\"PSNR scores for test images, mean : \", test_psnr.mean(), \", var :\", test_psnr.var())\n",
    "print(\"Average SSIM for test images, mean : \", test_ssim.mean(), \", var :\", test_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for train images, mean : \", train_psnr.mean(), \", var :\", train_psnr.var())\n",
    "print(\"Average SSIM for train images, mean : \", train_ssim.mean(), \", var :\", train_ssim.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on 20 images from the test set\n",
    "sub_dataset_size = 20\n",
    "indices = np.random.choice(len(full_test_dataset), sub_dataset_size, replace=False)\n",
    "predicted_images = PatchImageTool.predict_images_from_dataset_patches(exp, (1920, 1080), full_test_dataset, indices, device, \n",
    "                                                                      batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 4 images, real vs predicted\n",
    "\n",
    "low_res_tensor = []\n",
    "high_res_tensor = []\n",
    "\n",
    "for i in range(4):\n",
    "    index = indices[i]\n",
    "    image_index = full_test_dataset.get_index_for_image(index)\n",
    "\n",
    "    low_res_images, high_res = full_test_dataset.get_full_image(image_index)\n",
    "    low_res = low_res_images[chosen_upscale]\n",
    "\n",
    "    low_res_tensor.append(low_res)\n",
    "    high_res_tensor.append(high_res)\n",
    "\n",
    "PlotUtils.show_low_high_predicted(low_res_tensor, high_res_tensor, predicted_images[:len(low_res_tensor)], name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 4 images, predicted, bilinear and subtraction\n",
    "\n",
    "predicted_images_numpy = []\n",
    "bicubic_images_numpy = []\n",
    "subtraction_images_numpy = []\n",
    "\n",
    "for i in range(4):\n",
    "    index = indices[i]\n",
    "    image_index = full_test_dataset.get_index_for_image(index)\n",
    "\n",
    "    low_res_images, high_res = full_test_dataset.get_full_image(image_index)\n",
    "    low_res = low_res_images[chosen_upscale]\n",
    "\n",
    "    pred_high_res_image = torchUtil.tensor_to_numpy(predicted_images[i])\n",
    "    bicubic_image = torchUtil.resize_tensor_to_numpy(low_res, (pred_high_res_image.shape[0], pred_high_res_image.shape[1]))\n",
    "\n",
    "    predicted_images_numpy.append(pred_high_res_image)\n",
    "    bicubic_images_numpy.append(bicubic_image)\n",
    "    \n",
    "    subtraction_image = torchUtil.norm_numpy_image(pred_high_res_image - bicubic_image)\n",
    "    subtraction_images_numpy.append(subtraction_image)\n",
    "\n",
    "PlotUtils.show_predicted_interpolated_subtraction(predicted_images_numpy, bicubic_images_numpy, subtraction_images_numpy, \n",
    "                                                  name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean and var psnr and ssim for n images from the test set\n",
    "\n",
    "batch_size = full_test_dataset.get_number_patch_per_image(upscale_index=chosen_upscale) * 4\n",
    "\n",
    "sub_size_factor = 1\n",
    "sub_dataset_size = int(sub_size_factor * len(full_test_dataset) / full_test_dataset.get_number_patch_per_image(upscale_index=chosen_upscale))\n",
    "print(\"Number of images in full data set part\", sub_dataset_size)\n",
    "test_psnr, test_ssim = PatchImageTool.compute_metrics_dataset_batched(exp, (1920, 1080), full_test_dataset, sub_dataset_size, device, batch_size)\n",
    "\n",
    "# Compute the PSNR and SSIM for the bilinear image on a subset of the train set\n",
    "\n",
    "test_bicubic_psnr, test_bicubic_ssim = [], []\n",
    "\n",
    "for i in range(sub_dataset_size):\n",
    "    low_res_images, high_res = full_test_dataset.get_full_image(i)\n",
    "\n",
    "    low_res = low_res_images[chosen_upscale]\n",
    "\n",
    "    low_res_image = torchUtil.tensor_to_numpy(low_res)\n",
    "    high_res_image = torchUtil.tensor_to_numpy(high_res)\n",
    "\n",
    "    bicubic_image = torchUtil.resize_tensor_to_numpy(low_res, (high_res_image.shape[0], high_res_image.shape[1]))\n",
    "\n",
    "    test_bicubic_psnr.append(metrics.peak_signal_noise_ratio(high_res_image, bicubic_image))\n",
    "    test_bicubic_ssim.append(metrics.structural_similarity(high_res_image, bicubic_image, win_size=7, data_range=1,\n",
    "                                                            multichannel=True, channel_axis=2))\n",
    "\n",
    "# compute the mean and var psnr and ssim for 100 images from the train set\n",
    "\n",
    "sub_dataset_size = int(sub_size_factor * len(full_train_dataset) / full_train_dataset.get_number_patch_per_image(upscale_index=chosen_upscale))\n",
    "print(\"Number of images in full data set part\", sub_dataset_size)\n",
    "train_psnr, train_ssim = PatchImageTool.compute_metrics_dataset_batched(exp,  (1920, 1080), \n",
    "                                                                        full_train_dataset, sub_dataset_size, device, batch_size)\n",
    "\n",
    "train_bicubic_psnr, train_bicubic_ssim = [], []\n",
    "\n",
    "for i in range(sub_dataset_size):\n",
    "    low_res_images, high_res = full_train_dataset.get_full_image(i)\n",
    "    low_res = low_res_images[chosen_upscale]\n",
    "\n",
    "    low_res_image = torchUtil.tensor_to_numpy(low_res)\n",
    "    high_res_image = torchUtil.tensor_to_numpy(high_res)\n",
    "\n",
    "    bicubic_image = torchUtil.resize_tensor_to_numpy(low_res, (high_res_image.shape[0], high_res_image.shape[1]))\n",
    "\n",
    "    train_bicubic_psnr.append(metrics.peak_signal_noise_ratio(high_res_image, bicubic_image))\n",
    "    train_bicubic_ssim.append(metrics.structural_similarity(high_res_image, bicubic_image, win_size=7, \n",
    "                                                            data_range=1, multichannel=True, channel_axis=2))\n",
    "\n",
    "print(\"Average PSNR for test images\", test_psnr.mean(), \"Variance\", test_psnr.var())\n",
    "print(\"Average SSIM for test images\", test_ssim.mean(), \"Variance\", test_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for bicubic test images\", np.array(test_bicubic_psnr).mean(), \"Variance\", np.array(test_bicubic_psnr).var())\n",
    "print(\"Average SSIM for bicubic test images\", np.array(test_bicubic_ssim).mean(), \"Variance\", np.array(test_bicubic_ssim).var())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Average PSNR for train images\", train_psnr.mean(), \"Variance\", train_psnr.var())\n",
    "print(\"Average SSIM for train images\", train_ssim.mean(), \"Variance\", train_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for bicubic train images\", np.array(train_bicubic_psnr).mean(), \"Variance\", np.array(train_bicubic_psnr).var())\n",
    "print(\"Average SSIM for bicubic train images\", np.array(train_bicubic_ssim).mean(), \"Variance\", np.array(train_bicubic_ssim).var())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
