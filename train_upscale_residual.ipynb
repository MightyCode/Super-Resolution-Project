{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training file for UpscaleNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.nntools as nt\n",
    "from src.CarlaDataset import CarlaDatasetPatch\n",
    "from src.PytorchUtil import PytorchUtil as torchUtil\n",
    "\n",
    "from src.UpscaleNN import UpscaleResidualNN as UpscaleNN\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.metrics as metrics\n",
    "import platform  # Import the platform module to detect the OS\n",
    "\n",
    "device = None\n",
    "if platform.system() == 'Windows':  # Check if the OS is Windows\n",
    "    import torch_directml  # Import torch_directml only on Windows\n",
    "    device = torch_directml.device()\n",
    "\n",
    "\n",
    "if not device:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResolutionStatsManager(nt.StatsManager):\n",
    "    def __init__(self):\n",
    "        super(SuperResolutionStatsManager, self).__init__()\n",
    "\n",
    "    def init(self):\n",
    "        super(SuperResolutionStatsManager, self).init()\n",
    "        # Initializing `self.running_psnr`\n",
    "        self.running_psnr = 0\n",
    "        self.running_ssim = 0\n",
    "\n",
    "    def accumulate(self, loss, x, y, d):\n",
    "        super(SuperResolutionStatsManager, self).accumulate(loss, x, y, d)\n",
    "        # Updating `self.running_psnr`\n",
    "        d_numpy = d.detach().to('cpu').numpy()\n",
    "        y_numpy = y.detach().to('cpu').numpy()\n",
    "\n",
    "        self.running_psnr += metrics.peak_signal_noise_ratio(d_numpy, y_numpy)\n",
    "\n",
    "        current_ssim = 0\n",
    "\n",
    "        for i in range(d_numpy.shape[0]):\n",
    "            d_numpy_temp = np.moveaxis(d_numpy[i], [0, 1, 2], [2, 0, 1])\n",
    "            y_numpy_temp = np.moveaxis(y_numpy[i], [0, 1, 2], [2, 0, 1])\n",
    "\n",
    "            value_range = max(d_numpy_temp.max(), y_numpy_temp.max()) - min(d_numpy_temp.min(), y_numpy_temp.min())\n",
    "            \n",
    "            current_ssim += metrics.structural_similarity(d_numpy_temp, y_numpy_temp, win_size=7, data_range=value_range, multichannel=True, channel_axis=2)\n",
    "        \n",
    "        self.running_ssim += current_ssim / d_numpy.shape[0]\n",
    "\n",
    "    def summarize(self):\n",
    "        loss = super(SuperResolutionStatsManager, self).summarize()\n",
    "        psnr = self.running_psnr / (self.number_update+1e-9 )\n",
    "        ssim = self.running_ssim / (self.number_update+1e-9 )\n",
    "        return {'loss': loss, 'psnr': psnr, \"ssim\": ssim}\n",
    "\n",
    "def criterion(y, d):\n",
    "    return F.mse_loss(y, d)\n",
    "\n",
    "#show image\n",
    "def myimshow(image, ax=plt):\n",
    "    image = image.detach().to('cpu').numpy()\n",
    "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
    "    image[image < 0] = 0\n",
    "    image[image > 1] = 1\n",
    "    h = ax.imshow(image)\n",
    "    # ax.axis('off')\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_size = 256\n",
    "common_transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    common_transform,\n",
    "    #transforms.RandomRotation(degrees=10),\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    #transforms.RandomResizedCrop(size=(new_img_size, new_img_size), scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    common_transform,\n",
    "    #transforms.CenterCrop((new_img_size, new_img_size)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "#import your datasetclass\n",
    "\n",
    "PATCH_SIZE = 32\n",
    "\n",
    "full_train_dataset = CarlaDatasetPatch(\"1920x1080\", \"960x540\", \"train\", transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "full_test_dataset = CarlaDatasetPatch(\"1920x1080\", \"960x540\", \"test\", transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "train_dataset_patched = CarlaDatasetPatch(\"1920x1080\", \"960x540\", \"train\", transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "test_dataset_patched = CarlaDatasetPatch(\"1920x1080\", \"960x540\", \"test\", transforms=train_transform, download=True, patch_size=PATCH_SIZE)\n",
    "\n",
    "SUBSET_SIZE = 20000\n",
    "if len(train_dataset_patched) > SUBSET_SIZE:\n",
    "    train_dataset_patched.limit_dataset(SUBSET_SIZE)\n",
    "\n",
    "if len(test_dataset_patched) > SUBSET_SIZE * 0.2:\n",
    "    test_dataset_patched.limit_dataset(int(SUBSET_SIZE * 0.2))\n",
    "\n",
    "print(\"Size of sub train dataset\", len(train_dataset_patched))\n",
    "print(\"Size of sub test dataset\", len(test_dataset_patched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one full image for both train and test\n",
    "example1_low, example1_high = full_train_dataset[0]\n",
    "example2_low, example2_high = full_test_dataset[0]\n",
    "\n",
    "example1_low_image = torchUtil.tensor_to_image(example1_low)\n",
    "example1_high_image = torchUtil.tensor_to_image(example1_high)\n",
    "\n",
    "example2_low_image = torchUtil.tensor_to_image(example2_low)\n",
    "example2_high_image = torchUtil.tensor_to_image(example2_high)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "ax[0, 0].imshow(example1_low_image)\n",
    "ax[0, 0].set_title(\"Train Low resolution\")\n",
    "ax[0, 1].imshow(example1_high_image)\n",
    "ax[0, 1].set_title(\"Train High resolution\")\n",
    "ax[1, 0].imshow(example2_low_image)\n",
    "ax[1, 0].set_title(\"Test Low resolution\")\n",
    "ax[1, 1].imshow(example2_high_image)\n",
    "ax[1, 1].set_title(\"Test High resolution\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the patched dataset\n",
    "example1_low, example1_high = train_dataset_patched[0]\n",
    "example2_low, example2_high = test_dataset_patched[0]\n",
    "\n",
    "example1_low_image = torchUtil.tensor_to_image(example1_low)\n",
    "example1_high_image = torchUtil.tensor_to_image(example1_high)\n",
    "\n",
    "example2_low_image = torchUtil.tensor_to_image(example2_low)\n",
    "example2_high_image = torchUtil.tensor_to_image(example2_high)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "ax[0, 0].imshow(example1_low_image)\n",
    "ax[0, 0].set_title(\"Train Low resolution\")\n",
    "ax[0, 1].imshow(example1_high_image)\n",
    "ax[0, 1].set_title(\"Train High resolution\")\n",
    "ax[1, 0].imshow(example2_low_image)\n",
    "ax[1, 0].set_title(\"Test Low resolution\")\n",
    "ax[1, 1].imshow(example2_high_image)\n",
    "ax[1, 1].set_title(\"Test High resolution\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for the the predicted image, low resolution image and high resolution image in first row\n",
    "# plot Plot the loss, psnr and ssim curves in the second row\n",
    "def plot_images_and_metrics(exp, fig, axes, dataset, index): ##Only to use when perform_validation_during_training == True\n",
    "    low_res, high_res = dataset[index]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predicted_res = exp.net(low_res.to(device))[0]\n",
    "\n",
    "    axes[0][0].clear()\n",
    "    axes[0][1].clear()\n",
    "    axes[0][2].clear()\n",
    "    axes[1][0].clear()\n",
    "    axes[1][1].clear()\n",
    "    axes[1][2].clear()\n",
    "\n",
    "    low_res_image = torchUtil.tensor_to_image(low_res)\n",
    "    high_res_image = torchUtil.tensor_to_image(high_res)\n",
    "    predicted_res_image = torchUtil.tensor_to_image(predicted_res)\n",
    "\n",
    "    axes[0][0].set_title(f'Low res: {low_res_image.shape}')\n",
    "    axes[0][1].set_title(f'High res: {high_res_image.shape}')\n",
    "    axes[0][2].set_title(f'Predicted res: {predicted_res_image.shape}')\n",
    "\n",
    "\n",
    "    axes[0][0].imshow(low_res_image)\n",
    "    axes[0][1].imshow(high_res_image)\n",
    "    axes[0][2].imshow(predicted_res_image)\n",
    "\n",
    "    axes[1][0].plot([exp.history[k][0]['loss'] for k in range(exp.epoch)], label=\"Train loss\")\n",
    "    axes[1][1].plot([exp.history[k][0]['psnr'] for k in range(exp.epoch)], label=\"Train psnr\")\n",
    "    axes[1][2].plot([exp.history[k][0]['ssim'] for k in range(exp.epoch)], label=\"Train ssim\")\n",
    "\n",
    "    axes[1][0].plot([exp.history[k][1]['loss'] for k in range(exp.epoch)], label=\"Eval loss\")\n",
    "    axes[1][1].plot([exp.history[k][1]['psnr'] for k in range(exp.epoch)], label=\"Eval psnr\")\n",
    "    axes[1][2].plot([exp.history[k][1]['ssim'] for k in range(exp.epoch)], label=\"Eval ssim\")\n",
    "\n",
    "    axes[1][0].legend()\n",
    "    axes[1][0].set_xlabel(\"Epoch\")\n",
    "    axes[1][0].set_ylabel(\"Loss\")        \n",
    "    axes[1][1].legend()\n",
    "    axes[1][1].set_xlabel(\"Epoch\")\n",
    "    axes[1][1].set_ylabel(\"PSNR\") \n",
    "    axes[1][2].legend()\n",
    "    axes[1][2].set_xlabel(\"Epoch\")\n",
    "    axes[1][2].set_ylabel(\"SSIM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model on a small dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset_size = 30\n",
    "small_dataset = [train_dataset_patched[np.random.randint(len(train_dataset_patched))] for _ in range(small_dataset_size)]\n",
    "\n",
    "small_train_size = int(0.8 * len(small_dataset))\n",
    "small_valid_size = len(small_dataset) - small_train_size\n",
    "small_train_dataset, small_valid_dataset = torch.utils.data.random_split(small_dataset, [small_train_size, small_valid_size])\n",
    "\n",
    "print(\"Size of small_train_dataset:\", len(small_train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "r = UpscaleNN()\n",
    "r = r.to(device)\n",
    "# In mega bytes\n",
    "print(\"Size of model mb\", sum(p.numel() for p in r.parameters() if p.requires_grad) / (1024 * 1024))\n",
    "# Size of batch in mega bytes\n",
    "print(\"Size of batch mb\", small_dataset[0][0].shape[0] * small_dataset[0][0].shape[1] * small_dataset[0][0].shape[2] * 4 / (1024 * 1024))\n",
    "\n",
    "adam = torch.optim.Adam(r.parameters(), lr=lr)\n",
    "stats_manager = SuperResolutionStatsManager()\n",
    "path = \"results/smallbatchexperiment-upscale-resid\"\n",
    "exp = nt.Experiment(r, \n",
    "                    small_dataset, small_valid_dataset, \n",
    "                    adam, stats_manager, device, criterion, batch_size=1,\n",
    "                    output_dir=path, perform_validation_during_training=True)\n",
    "\n",
    "# Show number of parameters\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in r.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(12, 10))\n",
    "exp.run(num_epochs=300, plot=lambda exp: plot_images_and_metrics(exp, fig, axes, small_valid_dataset, np.random.randint(len(small_valid_dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show three images for a set and predict it\n",
    "def plot_images_from_model(model, dataset, num_images=1, indices=None):\n",
    "    num_images = max(num_images, len(indices) if indices else 0)\n",
    "\n",
    "    _, axes = plt.subplots(num_images, 3, figsize=(15, 5 * num_images))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        if indices:\n",
    "            low_res, high_res = dataset[indices[i]]\n",
    "            print(\"Chosen index\", indices[i])\n",
    "        else:\n",
    "            index = np.random.randint(len(dataset))\n",
    "            low_res, high_res = dataset[index]\n",
    "            print(\"Chosen index\", index)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_res = model.net(low_res.to(device))[0]\n",
    "\n",
    "        low_res_image = torchUtil.tensor_to_image(low_res)\n",
    "        high_res_image = torchUtil.tensor_to_image(high_res)\n",
    "        predicted_res_image = torchUtil.numpy_to_image(torchUtil.tensor_to_numpy(predicted_res))\n",
    "\n",
    "        axes[i, 0].set_title(f'Low res: {low_res_image.shape}')\n",
    "        axes[i, 1].set_title(f'High res: {high_res_image.shape}')\n",
    "        axes[i, 2].set_title(f'Predicted res: {predicted_res_image.shape}')\n",
    "\n",
    "        axes[i, 0].imshow(low_res_image)\n",
    "        axes[i, 1].imshow(high_res_image)\n",
    "        axes[i, 2].imshow(predicted_res_image)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.v2 import Resize\n",
    "\n",
    "def resize_tensor(tensor, size):\n",
    "    return Resize(size, antialias=True)(tensor)\n",
    "\n",
    "def resize_tensor_to_numpy(tensor, size):\n",
    "    return torchUtil.tensor_to_numpy(resize_tensor(tensor, size))\n",
    "\n",
    "def plot_predicted_and_billinear(model, dataset, num_images=1, indices=None):\n",
    "    num_images = max(num_images, len(indices) if indices else 0)\n",
    "\n",
    "    _, axes = plt.subplots(num_images, 3, figsize=(15, 5 * num_images))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        if indices:\n",
    "            low_res, _ = dataset[indices[i]]\n",
    "            print(\"Chosen index\", indices[i])\n",
    "        else:\n",
    "            index = np.random.randint(len(dataset))\n",
    "            low_res, _ = dataset[index]\n",
    "            print(\"Chosen index\", index)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predicted_torch = model.net(low_res.to(device))[0]\n",
    "\n",
    "        predicted_res = torchUtil.tensor_to_numpy(predicted_torch)\n",
    "                    \n",
    "        bilinear_image = resize_tensor_to_numpy(low_res, (predicted_res.shape[0], predicted_res.shape[1]))\n",
    "        subtraction_image = torchUtil.norm_numpy_image(predicted_res - bilinear_image)\n",
    "\n",
    "        print(subtraction_image.mean(), subtraction_image.std())\n",
    "\n",
    "        axes[i, 0].set_title(f'Predicted res: {predicted_res.shape}')\n",
    "        axes[i, 1].set_title(f'Bilinear res: {bilinear_image.shape}')\n",
    "        axes[i, 2].set_title(f'Substraction res: {subtraction_image.shape}')\n",
    "\n",
    "        axes[i, 0].imshow(torchUtil.numpy_to_image(predicted_res), vmin=0, vmax=1)\n",
    "        axes[i, 1].imshow(torchUtil.numpy_to_image(bilinear_image), vmin=0, vmax=1)\n",
    "        axes[i, 2].imshow(torchUtil.numpy_to_image(subtraction_image), vmin=subtraction_image.min(), vmax=subtraction_image.max())  \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_from_model(exp, small_dataset, indices=[0, 1, 2])\n",
    "\n",
    "plot_predicted_and_billinear(exp, small_dataset, indices=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model on a subsequent part of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take the sub part of the dataset from random indices\n",
    "train_size = int(0.8 * len(train_dataset_patched))\n",
    "valid_size = len(train_dataset_patched) - train_size\n",
    "\n",
    "train_sub_dataset, valid_sub_dataset = torch.utils.data.random_split(train_dataset_patched, [train_size, valid_size])\n",
    "\n",
    "print(\"Size of train_dataset: \", len(train_sub_dataset))\n",
    "print(\"Size of valid_dataset: \", len(valid_sub_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 512\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "r = UpscaleNN()\n",
    "r = r.to(device)\n",
    "adam = torch.optim.Adam(r.parameters(), lr=lr)\n",
    "stats_manager = SuperResolutionStatsManager()\n",
    "path = \"results/superresol-upscale-resid\"\n",
    "exp1 = nt.Experiment(r, \n",
    "                    train_sub_dataset, valid_sub_dataset, \n",
    "                    adam, stats_manager, device, criterion, \n",
    "                    batch_size=batch_size,\n",
    "                    output_dir=path, perform_validation_during_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(12, 12))\n",
    "exp1.run(num_epochs=20, plot=lambda exp: plot_images_and_metrics(exp, fig, axes, test_dataset_patched, np.random.randint(len(test_dataset_patched))))\n",
    "#exp1.run(num_epochs=3, plot=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_from_model(exp1, test_dataset_patched, num_images=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_from_model(exp1, test_dataset_patched, num_images=4)\n",
    "\n",
    "\n",
    "plot_predicted_and_billinear(exp, test_dataset_patched, num_images=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruct image from patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.PatchImageTool import PatchImageTool\n",
    "\n",
    "index_patch_train = np.random.randint(len(full_train_dataset))\n",
    "index_patch_test = np.random.randint(len(full_test_dataset))\n",
    "\n",
    "print(\"Choose index train\", index_patch_train, \"Choose index test\", index_patch_test)\n",
    "\n",
    "start_index_patch_train = full_train_dataset.get_index_start_patch(index_patch_train)\n",
    "start_index_patch_test = full_test_dataset.get_index_start_patch(index_patch_test)\n",
    "\n",
    "print (\"Start index patch train\", start_index_patch_train, \"Start index patch test\", start_index_patch_test)\n",
    "\n",
    "index_train = full_train_dataset.get_index_for_image(index_patch_train)\n",
    "index_test = full_test_dataset.get_index_for_image(index_patch_test)\n",
    "\n",
    "print (\"Index train\", index_train, \"Index test\", index_test)\n",
    "\n",
    "train_low_res, train_high_res = full_train_dataset.get_full_image(index_train)\n",
    "test_low_res, test_high_res = full_test_dataset.get_full_image(index_test)\n",
    "\n",
    "pred_high_res1 = PatchImageTool.predict_image_from_dataset_patches(exp1, (1920, 1080), full_train_dataset, index_patch_train, device)\n",
    "pred_high_res2 = PatchImageTool.predict_image_from_dataset_patches(exp1, (1920, 1080), full_test_dataset, index_patch_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test on one image from the train and test set\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(30, 10))\n",
    "\n",
    "train_low_res_image = torchUtil.tensor_to_image(train_low_res)\n",
    "train_high_res_image = torchUtil.tensor_to_image(train_high_res)\n",
    "pred_high_res1_image = torchUtil.tensor_to_image(pred_high_res1)\n",
    "\n",
    "axes[0][0].set_title(f'Train Low res: {train_low_res_image.shape}')\n",
    "axes[0][1].set_title(f'Train High res: {train_high_res_image.shape}')\n",
    "axes[0][2].set_title(f'Train Predicted res: {pred_high_res1_image.shape}')\n",
    "\n",
    "axes[0][0].imshow(train_low_res_image)\n",
    "axes[0][1].imshow(train_high_res_image)\n",
    "axes[0][2].imshow(pred_high_res1_image)\n",
    "\n",
    "test_low_res_image = torchUtil.tensor_to_image(test_low_res)\n",
    "test_high_res_image = torchUtil.tensor_to_image(test_high_res)\n",
    "pred_high_res2_image = torchUtil.tensor_to_image(pred_high_res2)\n",
    "\n",
    "axes[1][0].set_title(f'Test Low res: {test_low_res.shape}')\n",
    "axes[1][1].set_title(f'Test High res: {test_high_res.shape}')\n",
    "axes[1][2].set_title(f'Test Predicted res: {pred_high_res2_image.shape}')\n",
    "\n",
    "axes[1][0].imshow(test_low_res_image)\n",
    "axes[1][1].imshow(test_high_res_image)\n",
    "axes[1][2].imshow(pred_high_res2_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show predicted, bilinear and subtraction image\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(30, 10))\n",
    "\n",
    "pred_high_res1_numpy = torchUtil.tensor_to_numpy(pred_high_res1)\n",
    "pred_high_res2_numpy = torchUtil.tensor_to_numpy(pred_high_res2)\n",
    "\n",
    "bilinear_image1_numpy = resize_tensor_to_numpy(train_low_res, (pred_high_res1_image.shape[0], pred_high_res1_image.shape[1]))\n",
    "bilinear_image2_numpy = resize_tensor_to_numpy(test_low_res, (pred_high_res2_image.shape[0], pred_high_res2_image.shape[1]))\n",
    "\n",
    "subtraction_numpy = torchUtil.norm_numpy_image(pred_high_res1_numpy - bilinear_image1_numpy)\n",
    "subtraction_numpy =  torchUtil.norm_numpy_image(pred_high_res2_numpy - bilinear_image2_numpy)\n",
    "\n",
    "axes[0][0].set_title(f'Train Predicted res: {pred_high_res1_image.shape}')\n",
    "axes[0][1].set_title(f'Train Bilinear res: {bilinear_image1_numpy.shape}')\n",
    "axes[0][2].set_title(f'Train Subtraction res: {subtraction_numpy.shape}')\n",
    "\n",
    "axes[0][0].imshow(torchUtil.numpy_to_image(pred_high_res1_image), vmin=0, vmax=1)\n",
    "axes[0][1].imshow(torchUtil.numpy_to_image(bilinear_image1_numpy), vmin=0, vmax=1)\n",
    "axes[0][2].imshow(torchUtil.numpy_to_image(subtraction_numpy), vmin=subtraction_numpy.min(), vmax=subtraction_numpy.max())\n",
    "\n",
    "axes[1][0].set_title(f'Test Predicted res: {pred_high_res2_image.shape}')\n",
    "axes[1][1].set_title(f'Test Bilinear res: {bilinear_image2_numpy.shape}')\n",
    "\n",
    "axes[1][2].set_title(f'Test Subtraction res: {subtraction_numpy.shape}')\n",
    "\n",
    "axes[1][0].imshow(torchUtil.numpy_to_image(pred_high_res2_image), vmin=0, vmax=1)\n",
    "axes[1][1].imshow(torchUtil.numpy_to_image(bilinear_image2_numpy), vmin=0, vmax=1)\n",
    "axes[1][2].imshow(torchUtil.numpy_to_image(subtraction_numpy), vmin=subtraction_numpy.min(), vmax=subtraction_numpy.max())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PSNR and SSIM for the predicted image\n",
    "\n",
    "train_high_res_np = torchUtil.tensor_to_numpy(train_high_res)\n",
    "test_high_res_np = torchUtil.tensor_to_numpy(test_high_res)\n",
    "\n",
    "pred_high_res1_np = torchUtil.tensor_to_numpy(pred_high_res1)\n",
    "pred_high_res2_np = torchUtil.tensor_to_numpy(pred_high_res2)\n",
    "\n",
    "train_psnr = metrics.peak_signal_noise_ratio(train_high_res_np, pred_high_res1_np)\n",
    "train_ssim = metrics.structural_similarity(train_high_res_np, pred_high_res1_np, win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "test_psnr = metrics.peak_signal_noise_ratio(test_high_res_np, pred_high_res2_np)\n",
    "test_ssim = metrics.structural_similarity(test_high_res_np, pred_high_res2_np, win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "print(\"Train PSNR\", train_psnr, \"Train SSIM\", train_ssim)\n",
    "print(\"Test PSNR\", test_psnr, \"Test SSIM\", test_ssim)\n",
    "\n",
    "# Compute the PSNR and SSIM for the bilinear image\n",
    "\n",
    "train_bilinear_psnr = metrics.peak_signal_noise_ratio(train_high_res_np, bilinear_image1_numpy)\n",
    "train_bilinear_ssim = metrics.structural_similarity(train_high_res_np, bilinear_image1_numpy, win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "test_bilinear_psnr = metrics.peak_signal_noise_ratio(test_high_res_np, bilinear_image2_numpy)\n",
    "test_bilinear_ssim = metrics.structural_similarity(test_high_res_np, bilinear_image2_numpy, win_size=7, data_range=1, multichannel=True, channel_axis=2)\n",
    "\n",
    "print()\n",
    "print(\"Train bilinear PSNR\", train_bilinear_psnr, \"Train bilinear SSIM\", train_bilinear_ssim)\n",
    "print(\"Test bilinear PSNR\", test_bilinear_psnr, \"Test bilinear SSIM\", test_bilinear_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dataset_size = 10\n",
    "\n",
    "# Compute the PSNR and SSIM for the predicted image on a subset of the train set\n",
    "train_psnr, train_ssim = PatchImageTool.compute_metrics_dataset(exp1, full_train_dataset, sub_dataset_size, (1920, 1080), device)\n",
    "\n",
    "# Compute the PSNR and SSIM for the predicted image on a subset of the test set\n",
    "test_psnr, test_ssim = PatchImageTool.compute_metrics_dataset(exp1, full_test_dataset, sub_dataset_size, (1920, 1080), device)\n",
    "\n",
    "print()\n",
    "print(\"PSNR scores for test images, mean : \", test_psnr.mean(), \", var :\", test_psnr.var())\n",
    "print(\"Average SSIM for test images, mean : \", test_ssim.mean(), \", var :\", test_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for train images, mean : \", train_psnr.mean(), \", var :\", train_psnr.var())\n",
    "print(\"Average SSIM for train images, mean : \", train_ssim.mean(), \", var :\", train_ssim.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on 20 images from the test set\n",
    "sub_dataset_size = 20\n",
    "indices = np.random.choice(len(full_test_dataset), sub_dataset_size, replace=False)\n",
    "predicted_images = PatchImageTool.predict_images_from_dataset_patches(exp1, (1920, 1080), full_test_dataset, indices, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 4 images, real vs predicted\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(30, 20))\n",
    "\n",
    "for i in range(4):\n",
    "    index = indices[i]\n",
    "    image_index = full_test_dataset.get_index_for_image(index)\n",
    "\n",
    "    low_res, high_res = full_test_dataset.get_full_image(image_index)\n",
    "\n",
    "    low_res_image = torchUtil.tensor_to_image(low_res)\n",
    "    high_res_image = torchUtil.tensor_to_image(high_res)\n",
    "    pred_high_res_image = torchUtil.tensor_to_image(predicted_images[i])\n",
    "    \n",
    "    axes[i][0].set_title(f'Low res: {low_res_image.shape}')\n",
    "    axes[i][1].set_title(f'High res: {high_res_image.shape}')\n",
    "    axes[i][2].set_title(f'Predicted res: {pred_high_res_image.shape}')\n",
    "\n",
    "    axes[i][0].imshow(low_res_image, vmin=0, vmax=1)\n",
    "    axes[i][1].imshow(high_res_image, vmin=0, vmax=1)\n",
    "    axes[i][2].imshow(pred_high_res_image, vmin=0, vmax=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 4 images, predicted, bilinear and subtraction\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(30, 20))\n",
    "\n",
    "for i in range(4):\n",
    "    index = indices[i]\n",
    "    image_index = full_test_dataset.get_index_for_image(index)\n",
    "\n",
    "    low_res, high_res = full_test_dataset.get_full_image(image_index)\n",
    "\n",
    "    pred_high_res_image = torchUtil.tensor_to_numpy(predicted_images[i])\n",
    "    bilinear_image = resize_tensor_to_numpy(low_res, (pred_high_res_image.shape[0], pred_high_res_image.shape[1]))\n",
    "\n",
    "    print(low_res.shape, pred_high_res_image.shape, bilinear_image.shape, (pred_high_res_image.shape[0], pred_high_res_image.shape[1]))\n",
    "\n",
    "    subtraction_image = pred_high_res_image - bilinear_image\n",
    "\n",
    "    min_val = np.min(subtraction_image)\n",
    "    max_val = np.max(subtraction_image)\n",
    "    subtraction_image = (subtraction_image - min_val) / (max_val - min_val)\n",
    "    \n",
    "    axes[i][0].set_title(f'Predicted res: {pred_high_res_image.shape}')\n",
    "    axes[i][1].set_title(f'Bilinear res: {bilinear_image.shape}')\n",
    "    axes[i][2].set_title(f'Subtraction res: {subtraction_image.shape}')\n",
    "\n",
    "    axes[i][0].imshow(torchUtil.numpy_to_image(pred_high_res_image), vmin=0, vmax=1)\n",
    "    axes[i][1].imshow(torchUtil.numpy_to_image(bilinear_image), vmin=0, vmax=1)\n",
    "    axes[i][2].imshow(torchUtil.numpy_to_image(subtraction_image), vmin=subtraction_image.min(), vmax=subtraction_image.max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean and var psnr and ssim for n images from the test set\n",
    "\n",
    "batch_size = full_test_dataset.get_number_patch_per_image() * 4\n",
    "\n",
    "sub_size = 1\n",
    "sub_dataset_size = int(sub_size * len(full_test_dataset) / full_test_dataset.get_number_patch_per_image())\n",
    "print(\"Number of images in full data set part\", sub_dataset_size)\n",
    "test_psnr, test_ssim = PatchImageTool.compute_metrics_dataset_batched(exp1, (1920, 1080), full_test_dataset, sub_dataset_size, device, batch_size)\n",
    "\n",
    "# Compute the PSNR and SSIM for the bilinear image on a subset of the train set\n",
    "\n",
    "test_bilinear_psnr, test_bilinear_ssim = [], []\n",
    "\n",
    "for i in range(sub_dataset_size):\n",
    "    low_res, high_res = full_test_dataset.get_full_image(i)\n",
    "\n",
    "    low_res_image = torchUtil.tensor_to_numpy(low_res)\n",
    "    high_res_image = torchUtil.tensor_to_numpy(high_res)\n",
    "\n",
    "    bilinear_image = resize_tensor_to_numpy(low_res, (high_res_image.shape[0], high_res_image.shape[1]))\n",
    "\n",
    "    test_bilinear_psnr.append(metrics.peak_signal_noise_ratio(high_res_image, bilinear_image))\n",
    "    test_bilinear_ssim.append(metrics.structural_similarity(high_res_image, bilinear_image, win_size=7, data_range=1, multichannel=True, channel_axis=2))\n",
    "\n",
    "# compute the mean and var psnr and ssim for 100 images from the train set\n",
    "\n",
    "sub_dataset_size = int(sub_size * len(full_train_dataset) // full_train_dataset.get_number_patch_per_image())\n",
    "print(\"Number of images in full data set part\", sub_dataset_size)\n",
    "train_psnr, train_ssim = PatchImageTool.compute_metrics_dataset_batched(exp1,  (1920, 1080), full_train_dataset, sub_dataset_size, device, batch_size)\n",
    "\n",
    "\n",
    "train_bilinear_psnr, train_bilinear_ssim = [], []\n",
    "\n",
    "for i in range(sub_dataset_size):\n",
    "    low_res, high_res = full_train_dataset.get_full_image(i)\n",
    "\n",
    "    low_res_image = torchUtil.tensor_to_numpy(low_res)\n",
    "    high_res_image = torchUtil.tensor_to_numpy(high_res)\n",
    "\n",
    "    bilinear_image = resize_tensor_to_numpy(low_res, (high_res_image.shape[0], high_res_image.shape[1]))\n",
    "\n",
    "    train_bilinear_psnr.append(metrics.peak_signal_noise_ratio(high_res_image, bilinear_image))\n",
    "    train_bilinear_ssim.append(metrics.structural_similarity(high_res_image, bilinear_image, win_size=7, data_range=1, multichannel=True, channel_axis=2))\n",
    "\n",
    "print(\"Average PSNR for test images\", test_psnr.mean(), \"Variance\", test_psnr.var())\n",
    "print(\"Average SSIM for test images\", test_ssim.mean(), \"Variance\", test_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for bilinear test images\", np.array(test_bilinear_psnr).mean(), \"Variance\", np.array(test_bilinear_psnr).var())\n",
    "print(\"Average SSIM for bilinear test images\", np.array(test_bilinear_ssim).mean(), \"Variance\", np.array(test_bilinear_ssim).var())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Average PSNR for train images\", train_psnr.mean(), \"Variance\", train_psnr.var())\n",
    "print(\"Average SSIM for train images\", train_ssim.mean(), \"Variance\", train_ssim.var())\n",
    "\n",
    "print(\"Average PSNR for bilinear train images\", np.array(train_bilinear_psnr).mean(), \"Variance\", np.array(train_bilinear_psnr).var())\n",
    "print(\"Average SSIM for bilinear train images\", np.array(train_bilinear_ssim).mean(), \"Variance\", np.array(train_bilinear_ssim).var())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
